/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/nerfstudio/field_components/activations.py:32: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd(cast_inputs=torch.float32)
/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/nerfstudio/field_components/activations.py:39: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, g):
/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Difix3DTrainerConfig(
    _target=<class 'difix3d.difix3d_trainer.Difix3DTrainer'>,
    output_dir=PosixPath('outputs'),
    method_name='difix3d',
    experiment_name='difix3d_20250625_135724',
    project_name='difix3d',
    timestamp='2025-06-25_135731',
    machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),
    logging=LoggingConfig(
        relative_log_dir=PosixPath('.'),
        steps_per_log=10,
        max_buffer_size=20,
        local_writer=LocalWriterConfig(
            _target=<class 'nerfstudio.utils.writer.LocalWriter'>,
            enable=True,
            stats_to_track=(
                <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,
                <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,
                <EventName.CURR_TEST_PSNR: 'Test PSNR'>,
                <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,
                <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,
                <EventName.ETA: 'ETA (time)'>
            ),
            max_log_size=10
        ),
        profiler='basic'
    ),
    viewer=ViewerConfig(
        relative_log_filename='viewer_log_filename.txt',
        websocket_port=None,
        websocket_port_default=7007,
        websocket_host='0.0.0.0',
        num_rays_per_chunk=32768,
        max_num_display_images=512,
        quit_on_train_completion=True,
        image_format='jpeg',
        jpeg_quality=75,
        make_share_url=False,
        camera_frustum_scale=0.1,
        default_composite_depth=True
    ),
    pipeline=Difix3DPipelineConfig(
        _target=<class 'difix3d.difix3d_pipeline.Difix3DPipeline'>,
        datamanager=Difix3DDataManagerConfig(
            _target=<class 'difix3d.difix3d_datamanager.Difix3DDataManager'>,
            data=None,
            masks_on_gpu=False,
            images_on_gpu=False,
            dataparser=ColmapDataParserConfig(
                _target=<class 'nerfstudio.data.dataparsers.colmap_dataparser.ColmapDataParser'>,
                data=PosixPath('/home/azureuser/datasets/colmap_workspace'),
                scale_factor=1.0,
                downscale_factor=1,
                downscale_rounding_mode='floor',
                scene_scale=1.0,
                orientation_method='none',
                center_method='none',
                auto_scale_poses=False,
                assume_colmap_world_coordinate_convention=True,
                eval_mode='interval',
                train_split_fraction=0.9,
                eval_interval=8,
                depth_unit_scale_factor=0.001,
                images_path=PosixPath('images'),
                masks_path=None,
                depths_path=None,
                colmap_path=PosixPath('colmap/sparse/0'),
                load_3D_points=True,
                max_2D_matches_per_3D_point=0
            ),
            train_num_rays_per_batch=4096,
            train_num_images_to_sample_from=-1,
            train_num_times_to_repeat_images=-1,
            eval_num_rays_per_batch=4096,
            eval_num_images_to_sample_from=-1,
            eval_num_times_to_repeat_images=-1,
            eval_image_indices=(0,),
            collate_fn=<function nerfstudio_collate at 0x7780225663b0>,
            camera_res_scale_factor=1.0,
            patch_size=32,
            camera_optimizer=None,
            pixel_sampler=PixelSamplerConfig(
                _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,
                num_rays_per_batch=4096,
                keep_full_image=False,
                is_equirectangular=False,
                ignore_mask=False,
                fisheye_crop_radius=None,
                rejection_sample_mask=True,
                max_num_iterations=100
            )
        ),
        model=Difix3DModelConfig(
            _target=<class 'difix3d.difix3d.Difix3DModel'>,
            enable_collider=True,
            collider_params={'near_plane': 2.0, 'far_plane': 6.0},
            loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},
            eval_num_rays_per_chunk=32768,
            prompt=None,
            near_plane=0.05,
            far_plane=1000.0,
            background_color='last_sample',
            hidden_dim=64,
            hidden_dim_color=64,
            hidden_dim_transient=64,
            num_levels=16,
            base_res=16,
            max_res=2048,
            log2_hashmap_size=19,
            features_per_level=2,
            num_proposal_samples_per_ray=(256, 96),
            num_nerf_samples_per_ray=48,
            proposal_update_every=5,
            proposal_warmup=5000,
            num_proposal_iterations=2,
            use_same_proposal_network=False,
            proposal_net_args_list=[
                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},
                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}
            ],
            proposal_initial_sampler='piecewise',
            interlevel_loss_mult=1.0,
            distortion_loss_mult=0.002,
            orientation_loss_mult=0.0001,
            pred_normal_loss_mult=0.001,
            use_proposal_weight_anneal=True,
            use_appearance_embedding=True,
            use_average_appearance_embedding=True,
            proposal_weights_anneal_slope=10.0,
            proposal_weights_anneal_max_num_iters=1000,
            use_single_jitter=True,
            predict_normals=False,
            disable_scene_contraction=False,
            use_gradient_scaling=False,
            implementation='tcnn',
            appearance_embed_dim=0,
            average_init_density=0.01,
            camera_optimizer=CameraOptimizerConfig(
                _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,
                mode='off',
                trans_l2_penalty=0.01,
                rot_l2_penalty=0.001,
                optimizer=None,
                scheduler=None
            ),
            disable_camera_optimizer=False,
            freeze_appearance_embedding=False
        ),
        steps_per_fix=2000,
        steps_per_val=5000
    ),
    optimizers={
        'proposal_networks': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.01,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': ExponentialDecaySchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,
                lr_pre_warmup=1e-08,
                lr_final=0.0001,
                warmup_steps=0,
                max_steps=200000,
                ramp='cosine'
            )
        },
        'fields': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.01,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': ExponentialDecaySchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,
                lr_pre_warmup=1e-08,
                lr_final=0.0001,
                warmup_steps=0,
                max_steps=200000,
                ramp='cosine'
            )
        },
        'camera_opt': {
            'optimizer': AdamOptimizerConfig(
                _target=<class 'torch.optim.adam.Adam'>,
                lr=0.001,
                eps=1e-15,
                max_norm=None,
                weight_decay=0
            ),
            'scheduler': ExponentialDecaySchedulerConfig(
                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,
                lr_pre_warmup=1e-08,
                lr_final=0.0001,
                warmup_steps=0,
                max_steps=5000,
                ramp='cosine'
            )
        }
    },
    vis='viewer',
    data=None,
    prompt=None,
    relative_model_dir=PosixPath('nerfstudio_models'),
    load_scheduler=True,
    steps_per_save=2000,
    steps_per_eval_batch=500,
    steps_per_eval_image=500,
    steps_per_eval_all_images=25000,
    max_num_iterations=30000,
    mixed_precision=True,
    use_grad_scaler=False,
    save_only_latest_checkpoint=True,
    load_dir=None,
    load_step=None,
    load_config=None,
    load_checkpoint=None,
    log_gradients=False,
    gradient_accumulation_steps={},
    start_paused=False
)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[13:57:31] Saving config to:                                                                    experiment_config.py:136
           outputs/difix3d_20250625_135724/difix3d/2025-06-25_135731/config.yml                                         
/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/nerfstudio/engine/trainer.py:137: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler(enabled=self.use_grad_scaler)
           Saving checkpoints to:                                                                         trainer.py:142
           outputs/difix3d_20250625_135724/difix3d/2025-06-25_135731/nerfstudio_models                                  
Setting up training dataset...
Caching all 359 images.

Setting up evaluation dataset...
Caching all 52 images.


WARNING: Using a slow implementation for the SHEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the NeRFEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLPWithHashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the HashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the HashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch

Downloading: "https://download.pytorch.org/models/alexnet-owt-7be5be79.pth" to /home/azureuser/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth
  0%|          | 0.00/233M [00:00<?, ?B/s] 14%|â–ˆâ–        | 33.5M/233M [00:00<00:00, 350MB/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 79.8M/233M [00:00<00:00, 429MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 125M/233M [00:00<00:00, 450MB/s]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 171M/233M [00:00<00:00, 462MB/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217M/233M [00:00<00:00, 468MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:00<00:00, 454MB/s]
/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/torchmetrics/functional/image/lpips.py:332: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location="cpu"), strict=False)

WARNING: Using a slow implementation for the SHEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the NeRFEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLPWithHashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the HashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the HashEncoding module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch


WARNING: Using a slow implementation for the MLP module. 
ğŸƒ ğŸƒ Install tcnn for speedups ğŸƒ ğŸƒ
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch

/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files:  21%|â–ˆâ–ˆâ–       | 3/14 [00:00<00:00, 29.34it/s]Fetching 14 files:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6/14 [00:04<00:07,  1.03it/s]Fetching 14 files:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:17<00:08,  2.17s/it]Fetching 14 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:17<00:00,  1.28s/it]
Keyword arguments {'trust_remote_code': True} are not expected by DifixPipeline and will be ignored.
Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]Loading pipeline components...:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  4.02it/s]Loading pipeline components...:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05<00:09,  3.05s/it]/home/azureuser/miniconda3/envs/difix/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
Loading pipeline components...:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05<00:03,  1.71s/it]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.08s/it]
You have disabled the safety checker for <class 'src.pipeline_difix.DifixPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚             â•·                       â”‚
â”‚   HTTP      â”‚ http://0.0.0.0:7007   â”‚
â”‚   Websocket â”‚ ws://0.0.0.0:7007     â”‚
â”‚             â•µ                       â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
